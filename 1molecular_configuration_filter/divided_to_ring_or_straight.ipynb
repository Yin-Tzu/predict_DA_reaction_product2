{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "divided_to_ring_or_straight.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yin-Tzu/predict_DA_reaction_product2/blob/main/divided_to_ring_or_straight/divided_to_ring_or_straight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o3bqKT6yaWM"
      },
      "source": [
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import cv2\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "xy=np.load('NN.zip')\n",
        "X_train, y_train_label, X_test, y_test_label,X_valid,y_valid_label=xy['X_train'],xy['y_train_label'],xy['X_test'],xy['y_test_label'],xy['X_valid'],xy['y_valid_label']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJI9B8RZwCmn",
        "outputId": "9f97e164-b7d9-47dc-d977-c7bcc9db35ed"
      },
      "source": [
        "y_TrainOneHot = tf.keras.utils.to_categorical(y_train_label)  # One-Hot编码\n",
        "y_TestOneHot = tf.keras.utils.to_categorical(y_test_label)\n",
        "y_ValidOneHot = tf.keras.utils.to_categorical(y_valid_label)  # One-Hot编码\n",
        "print(X_train.shape, y_train_label.shape, X_test.shape, y_test_label.shape,X_valid.shape,y_valid_label.shape)\n",
        "tStart = time.time()#計時開始\n",
        "\n",
        "model = tf.keras.models.Sequential()  # 调用Sequential模型\n",
        "model.add(layers.Conv2D(input_shape=(300,300, 3), filters=16, kernel_size=(3,3), kernel_initializer='TruncatedNormal', strides=1, padding='same', activation='relu', name='conv1'))  # 10*10\n",
        "model.add(layers.AveragePooling2D(pool_size=(3,3), strides=2, padding='same', name='pool1'))  # 5*5\n",
        "model.add(layers.Conv2D(filters=16, kernel_size=(3,3), kernel_initializer='TruncatedNormal', strides=1, padding='same', activation='relu', name='conv3'))  # 10*10\n",
        "model.add(layers.MaxPooling2D(pool_size=(3,3), strides=2, padding='same', name='pool3'))\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3,3), kernel_initializer='TruncatedNormal', strides=1, padding='same', activation='relu', name='conv2'))  # 10*10\n",
        "model.add(layers.MaxPooling2D(pool_size=(3,3), strides=2, padding='same', name='pool2'))  # 5*5\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3,3), kernel_initializer='TruncatedNormal', strides=1, padding='same', activation='relu', name='conv4'))  # 10*10\n",
        "model.add(layers.MaxPooling2D(pool_size=(3,3), strides=2, padding='same', name='pool4'))  # 5*5\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3,3), kernel_initializer='TruncatedNormal', strides=1, padding='same', activation='relu', name='conv5'))  # 10*10\n",
        "model.add(layers.MaxPooling2D(pool_size=(3,3), strides=2, padding='same', name='pool5'))  # 5*5\n",
        "#model.add(layers.Flatten(name='flatten'))\n",
        "#model.add(layers.Dense(units=64, kernel_initializer='TruncatedNormal', activation='relu'))\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dropout(0.1))  #在 0 和 1 之间浮动。需要丢弃的输入比例。\n",
        "model.add(layers.Dense(units=2,kernel_initializer='TruncatedNormal', activation='softmax'))#,input_dim=100\n",
        "\n",
        "print(model.summary())\n",
        "#batch_size = 2\n",
        "# 模型的训练 编译模型\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.00005)# 3*3\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])  # metrics是训练和测试期间的模型评估标准。\n",
        "\n",
        "# 监控val_loss，当连续40轮变化小于0.0001时启动early stopping\n",
        "#es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=40, min_delta=0.0001)\n",
        "\n",
        "# 训练模型\n",
        "train_history = model.fit(x=X_train, y=y_TrainOneHot, validation_data=(X_valid, y_ValidOneHot), epochs=400, batch_size=70, verbose=2)\n",
        "#train_history = model.fit_generator(generator(X_train, y_train_label, batch_size), epochs=100, steps_per_epoch=len(X_train)// batch_size,validation_data=generator(X_valid, y_valid_label, batch_size),validation_steps=len(X_valid) // batch_size, verbose=2,workers=5, use_multiprocessing=True)#validation_data=generator(X_test, y_test_label, batch_size),validation_steps=len(X_test) // batch_size\n",
        "# 查看训练过程，之前的训练步骤的值都保存在这里面。这里共有loss,accuracy,val_loss,val_accuracy四个参数\n",
        "print(train_history.history)\n",
        "\n",
        "# 將模型儲存至 HDF5 檔案中\n",
        "model.save('my_model2.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "\n",
        "scores = model.evaluate(X_test,y_TestOneHot)\n",
        "#scores = model.evaluate_generator(generator(X_test, y_test_label, batch_size),steps=len(X_test)// batch_size)\n",
        "print('loss, accuracy=',scores) #显示测试准确率[1]\n",
        "\n",
        "prediction = model.predict_classes(X_test)\n",
        "# 返回预测属于某标签的概率\n",
        "y_score = model.predict_proba(X_test)\n",
        "\n",
        "t2 = time.time()#計時結束\n",
        "#列印結果\n",
        "print(\"It cost %f sec\" % (t2 - tStart))  #會自動做近位\n",
        "print(t2 - tStart)  #原型長這樣"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3600, 300, 300, 3) (3600,) (1200, 300, 300, 3) (1200,) (1200, 300, 300, 3) (1200,)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 300, 300, 16)      448       \n",
            "_________________________________________________________________\n",
            "pool1 (AveragePooling2D)     (None, 150, 150, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 150, 150, 16)      2320      \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 75, 75, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 75, 75, 32)        4640      \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 38, 38, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 38, 38, 64)        18496     \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 19, 19, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 19, 19, 64)        36928     \n",
            "_________________________________________________________________\n",
            "pool5 (MaxPooling2D)         (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 62,962\n",
            "Trainable params: 62,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/400\n",
            "52/52 - 39s - loss: 0.7104 - accuracy: 0.5525 - val_loss: 0.6089 - val_accuracy: 0.9242\n",
            "Epoch 2/400\n",
            "52/52 - 6s - loss: 0.5816 - accuracy: 0.7275 - val_loss: 0.4896 - val_accuracy: 0.9033\n",
            "Epoch 3/400\n",
            "52/52 - 6s - loss: 0.4600 - accuracy: 0.8189 - val_loss: 0.3439 - val_accuracy: 0.9175\n",
            "Epoch 4/400\n",
            "52/52 - 6s - loss: 0.3561 - accuracy: 0.8672 - val_loss: 0.2742 - val_accuracy: 0.9033\n",
            "Epoch 5/400\n",
            "52/52 - 6s - loss: 0.3069 - accuracy: 0.8800 - val_loss: 0.2361 - val_accuracy: 0.9142\n",
            "Epoch 6/400\n",
            "52/52 - 6s - loss: 0.2766 - accuracy: 0.8914 - val_loss: 0.2190 - val_accuracy: 0.9183\n",
            "Epoch 7/400\n",
            "52/52 - 6s - loss: 0.2628 - accuracy: 0.8942 - val_loss: 0.2171 - val_accuracy: 0.9025\n",
            "Epoch 8/400\n",
            "52/52 - 6s - loss: 0.2581 - accuracy: 0.8900 - val_loss: 0.2069 - val_accuracy: 0.9250\n",
            "Epoch 9/400\n",
            "52/52 - 6s - loss: 0.2526 - accuracy: 0.8947 - val_loss: 0.2059 - val_accuracy: 0.9167\n",
            "Epoch 10/400\n",
            "52/52 - 6s - loss: 0.2493 - accuracy: 0.8978 - val_loss: 0.2030 - val_accuracy: 0.9250\n",
            "Epoch 11/400\n",
            "52/52 - 6s - loss: 0.2496 - accuracy: 0.8994 - val_loss: 0.2029 - val_accuracy: 0.9150\n",
            "Epoch 12/400\n",
            "52/52 - 6s - loss: 0.2460 - accuracy: 0.8964 - val_loss: 0.2017 - val_accuracy: 0.9317\n",
            "Epoch 13/400\n",
            "52/52 - 6s - loss: 0.2464 - accuracy: 0.8956 - val_loss: 0.2048 - val_accuracy: 0.9083\n",
            "Epoch 14/400\n",
            "52/52 - 6s - loss: 0.2377 - accuracy: 0.8981 - val_loss: 0.2008 - val_accuracy: 0.9375\n",
            "Epoch 15/400\n",
            "52/52 - 6s - loss: 0.2414 - accuracy: 0.8964 - val_loss: 0.1963 - val_accuracy: 0.9283\n",
            "Epoch 16/400\n",
            "52/52 - 6s - loss: 0.2354 - accuracy: 0.9031 - val_loss: 0.1954 - val_accuracy: 0.9225\n",
            "Epoch 17/400\n",
            "52/52 - 6s - loss: 0.2429 - accuracy: 0.8931 - val_loss: 0.1939 - val_accuracy: 0.9225\n",
            "Epoch 18/400\n",
            "52/52 - 6s - loss: 0.2296 - accuracy: 0.9058 - val_loss: 0.1906 - val_accuracy: 0.9258\n",
            "Epoch 19/400\n",
            "52/52 - 6s - loss: 0.2285 - accuracy: 0.9058 - val_loss: 0.1944 - val_accuracy: 0.9092\n",
            "Epoch 20/400\n",
            "52/52 - 6s - loss: 0.2290 - accuracy: 0.9058 - val_loss: 0.2031 - val_accuracy: 0.9008\n",
            "Epoch 21/400\n",
            "52/52 - 6s - loss: 0.2262 - accuracy: 0.9022 - val_loss: 0.1860 - val_accuracy: 0.9333\n",
            "Epoch 22/400\n",
            "52/52 - 6s - loss: 0.2291 - accuracy: 0.9003 - val_loss: 0.2036 - val_accuracy: 0.9408\n",
            "Epoch 23/400\n",
            "52/52 - 6s - loss: 0.2308 - accuracy: 0.9025 - val_loss: 0.1926 - val_accuracy: 0.9433\n",
            "Epoch 24/400\n",
            "52/52 - 6s - loss: 0.2211 - accuracy: 0.9078 - val_loss: 0.1880 - val_accuracy: 0.9092\n",
            "Epoch 25/400\n",
            "52/52 - 6s - loss: 0.2168 - accuracy: 0.9069 - val_loss: 0.1795 - val_accuracy: 0.9233\n",
            "Epoch 26/400\n",
            "52/52 - 6s - loss: 0.2126 - accuracy: 0.9089 - val_loss: 0.1804 - val_accuracy: 0.9417\n",
            "Epoch 27/400\n",
            "52/52 - 6s - loss: 0.2083 - accuracy: 0.9114 - val_loss: 0.1739 - val_accuracy: 0.9408\n",
            "Epoch 28/400\n",
            "52/52 - 6s - loss: 0.2077 - accuracy: 0.9142 - val_loss: 0.1708 - val_accuracy: 0.9350\n",
            "Epoch 29/400\n",
            "52/52 - 6s - loss: 0.2032 - accuracy: 0.9144 - val_loss: 0.1705 - val_accuracy: 0.9233\n",
            "Epoch 30/400\n",
            "52/52 - 6s - loss: 0.2059 - accuracy: 0.9144 - val_loss: 0.1649 - val_accuracy: 0.9350\n",
            "Epoch 31/400\n",
            "52/52 - 6s - loss: 0.1922 - accuracy: 0.9189 - val_loss: 0.1666 - val_accuracy: 0.9217\n",
            "Epoch 32/400\n",
            "52/52 - 6s - loss: 0.1933 - accuracy: 0.9175 - val_loss: 0.1621 - val_accuracy: 0.9467\n",
            "Epoch 33/400\n",
            "52/52 - 6s - loss: 0.1894 - accuracy: 0.9192 - val_loss: 0.1532 - val_accuracy: 0.9342\n",
            "Epoch 34/400\n",
            "52/52 - 6s - loss: 0.1843 - accuracy: 0.9222 - val_loss: 0.1679 - val_accuracy: 0.9492\n",
            "Epoch 35/400\n",
            "52/52 - 6s - loss: 0.1787 - accuracy: 0.9261 - val_loss: 0.1420 - val_accuracy: 0.9475\n",
            "Epoch 36/400\n",
            "52/52 - 6s - loss: 0.1702 - accuracy: 0.9247 - val_loss: 0.1387 - val_accuracy: 0.9475\n",
            "Epoch 37/400\n",
            "52/52 - 6s - loss: 0.1686 - accuracy: 0.9275 - val_loss: 0.1342 - val_accuracy: 0.9483\n",
            "Epoch 38/400\n",
            "52/52 - 6s - loss: 0.1604 - accuracy: 0.9292 - val_loss: 0.1516 - val_accuracy: 0.9325\n",
            "Epoch 39/400\n",
            "52/52 - 6s - loss: 0.1600 - accuracy: 0.9322 - val_loss: 0.1203 - val_accuracy: 0.9533\n",
            "Epoch 40/400\n",
            "52/52 - 6s - loss: 0.1462 - accuracy: 0.9383 - val_loss: 0.1143 - val_accuracy: 0.9550\n",
            "Epoch 41/400\n",
            "52/52 - 6s - loss: 0.1391 - accuracy: 0.9411 - val_loss: 0.1069 - val_accuracy: 0.9558\n",
            "Epoch 42/400\n",
            "52/52 - 6s - loss: 0.1339 - accuracy: 0.9469 - val_loss: 0.1034 - val_accuracy: 0.9575\n",
            "Epoch 43/400\n",
            "52/52 - 6s - loss: 0.1284 - accuracy: 0.9456 - val_loss: 0.0991 - val_accuracy: 0.9675\n",
            "Epoch 44/400\n",
            "52/52 - 6s - loss: 0.1211 - accuracy: 0.9514 - val_loss: 0.0955 - val_accuracy: 0.9675\n",
            "Epoch 45/400\n",
            "52/52 - 6s - loss: 0.1149 - accuracy: 0.9542 - val_loss: 0.0850 - val_accuracy: 0.9742\n",
            "Epoch 46/400\n",
            "52/52 - 6s - loss: 0.1039 - accuracy: 0.9581 - val_loss: 0.0788 - val_accuracy: 0.9750\n",
            "Epoch 47/400\n",
            "52/52 - 6s - loss: 0.1036 - accuracy: 0.9608 - val_loss: 0.0737 - val_accuracy: 0.9775\n",
            "Epoch 48/400\n",
            "52/52 - 6s - loss: 0.0970 - accuracy: 0.9656 - val_loss: 0.0733 - val_accuracy: 0.9758\n",
            "Epoch 49/400\n",
            "52/52 - 6s - loss: 0.0890 - accuracy: 0.9661 - val_loss: 0.0674 - val_accuracy: 0.9758\n",
            "Epoch 50/400\n",
            "52/52 - 6s - loss: 0.0831 - accuracy: 0.9736 - val_loss: 0.0692 - val_accuracy: 0.9825\n",
            "Epoch 51/400\n",
            "52/52 - 6s - loss: 0.0819 - accuracy: 0.9736 - val_loss: 0.0566 - val_accuracy: 0.9842\n",
            "Epoch 52/400\n",
            "52/52 - 6s - loss: 0.0796 - accuracy: 0.9719 - val_loss: 0.0536 - val_accuracy: 0.9833\n",
            "Epoch 53/400\n",
            "52/52 - 6s - loss: 0.0713 - accuracy: 0.9781 - val_loss: 0.0574 - val_accuracy: 0.9883\n",
            "Epoch 54/400\n",
            "52/52 - 6s - loss: 0.0715 - accuracy: 0.9764 - val_loss: 0.0473 - val_accuracy: 0.9925\n",
            "Epoch 55/400\n",
            "52/52 - 6s - loss: 0.0631 - accuracy: 0.9828 - val_loss: 0.0466 - val_accuracy: 0.9833\n",
            "Epoch 56/400\n",
            "52/52 - 6s - loss: 0.0622 - accuracy: 0.9822 - val_loss: 0.0416 - val_accuracy: 0.9942\n",
            "Epoch 57/400\n",
            "52/52 - 6s - loss: 0.0584 - accuracy: 0.9825 - val_loss: 0.0406 - val_accuracy: 0.9917\n",
            "Epoch 58/400\n",
            "52/52 - 6s - loss: 0.0587 - accuracy: 0.9844 - val_loss: 0.0418 - val_accuracy: 0.9942\n",
            "Epoch 59/400\n",
            "52/52 - 6s - loss: 0.0537 - accuracy: 0.9850 - val_loss: 0.0357 - val_accuracy: 0.9933\n",
            "Epoch 60/400\n",
            "52/52 - 6s - loss: 0.0502 - accuracy: 0.9878 - val_loss: 0.0382 - val_accuracy: 0.9917\n",
            "Epoch 61/400\n",
            "52/52 - 6s - loss: 0.0553 - accuracy: 0.9864 - val_loss: 0.0438 - val_accuracy: 0.9892\n",
            "Epoch 62/400\n",
            "52/52 - 6s - loss: 0.0545 - accuracy: 0.9853 - val_loss: 0.0359 - val_accuracy: 0.9950\n",
            "Epoch 63/400\n",
            "52/52 - 6s - loss: 0.0525 - accuracy: 0.9844 - val_loss: 0.0316 - val_accuracy: 0.9933\n",
            "Epoch 64/400\n",
            "52/52 - 6s - loss: 0.0422 - accuracy: 0.9897 - val_loss: 0.0291 - val_accuracy: 0.9933\n",
            "Epoch 65/400\n",
            "52/52 - 6s - loss: 0.0412 - accuracy: 0.9897 - val_loss: 0.0380 - val_accuracy: 0.9917\n",
            "Epoch 66/400\n",
            "52/52 - 6s - loss: 0.0432 - accuracy: 0.9892 - val_loss: 0.0276 - val_accuracy: 0.9933\n",
            "Epoch 67/400\n",
            "52/52 - 6s - loss: 0.0413 - accuracy: 0.9894 - val_loss: 0.0294 - val_accuracy: 0.9950\n",
            "Epoch 68/400\n",
            "52/52 - 6s - loss: 0.0378 - accuracy: 0.9889 - val_loss: 0.0278 - val_accuracy: 0.9950\n",
            "Epoch 69/400\n",
            "52/52 - 6s - loss: 0.0451 - accuracy: 0.9883 - val_loss: 0.0250 - val_accuracy: 0.9942\n",
            "Epoch 70/400\n",
            "52/52 - 6s - loss: 0.0341 - accuracy: 0.9922 - val_loss: 0.0240 - val_accuracy: 0.9942\n",
            "Epoch 71/400\n",
            "52/52 - 6s - loss: 0.0367 - accuracy: 0.9914 - val_loss: 0.0281 - val_accuracy: 0.9950\n",
            "Epoch 72/400\n",
            "52/52 - 6s - loss: 0.0326 - accuracy: 0.9914 - val_loss: 0.0229 - val_accuracy: 0.9950\n",
            "Epoch 73/400\n",
            "52/52 - 6s - loss: 0.0327 - accuracy: 0.9919 - val_loss: 0.0215 - val_accuracy: 0.9933\n",
            "Epoch 74/400\n",
            "52/52 - 6s - loss: 0.0300 - accuracy: 0.9928 - val_loss: 0.0208 - val_accuracy: 0.9942\n",
            "Epoch 75/400\n",
            "52/52 - 6s - loss: 0.0330 - accuracy: 0.9914 - val_loss: 0.0238 - val_accuracy: 0.9958\n",
            "Epoch 76/400\n",
            "52/52 - 6s - loss: 0.0304 - accuracy: 0.9936 - val_loss: 0.0202 - val_accuracy: 0.9958\n",
            "Epoch 77/400\n",
            "52/52 - 6s - loss: 0.0361 - accuracy: 0.9886 - val_loss: 0.0312 - val_accuracy: 0.9933\n",
            "Epoch 78/400\n",
            "52/52 - 6s - loss: 0.0290 - accuracy: 0.9922 - val_loss: 0.0227 - val_accuracy: 0.9950\n",
            "Epoch 79/400\n",
            "52/52 - 6s - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.0217 - val_accuracy: 0.9950\n",
            "Epoch 80/400\n",
            "52/52 - 6s - loss: 0.0266 - accuracy: 0.9939 - val_loss: 0.0208 - val_accuracy: 0.9950\n",
            "Epoch 81/400\n",
            "52/52 - 6s - loss: 0.0273 - accuracy: 0.9928 - val_loss: 0.0247 - val_accuracy: 0.9950\n",
            "Epoch 82/400\n",
            "52/52 - 6s - loss: 0.0354 - accuracy: 0.9919 - val_loss: 0.0193 - val_accuracy: 0.9950\n",
            "Epoch 83/400\n",
            "52/52 - 6s - loss: 0.0290 - accuracy: 0.9922 - val_loss: 0.0172 - val_accuracy: 0.9950\n",
            "Epoch 84/400\n",
            "52/52 - 6s - loss: 0.0247 - accuracy: 0.9939 - val_loss: 0.0206 - val_accuracy: 0.9950\n",
            "Epoch 85/400\n",
            "52/52 - 6s - loss: 0.0257 - accuracy: 0.9928 - val_loss: 0.0275 - val_accuracy: 0.9942\n",
            "Epoch 86/400\n",
            "52/52 - 6s - loss: 0.0252 - accuracy: 0.9931 - val_loss: 0.0164 - val_accuracy: 0.9950\n",
            "Epoch 87/400\n",
            "52/52 - 6s - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.0162 - val_accuracy: 0.9967\n",
            "Epoch 88/400\n",
            "52/52 - 6s - loss: 0.0256 - accuracy: 0.9942 - val_loss: 0.0156 - val_accuracy: 0.9967\n",
            "Epoch 89/400\n",
            "52/52 - 6s - loss: 0.0230 - accuracy: 0.9939 - val_loss: 0.0200 - val_accuracy: 0.9950\n",
            "Epoch 90/400\n",
            "52/52 - 6s - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.0168 - val_accuracy: 0.9967\n",
            "Epoch 91/400\n",
            "52/52 - 6s - loss: 0.0296 - accuracy: 0.9917 - val_loss: 0.0156 - val_accuracy: 0.9967\n",
            "Epoch 92/400\n",
            "52/52 - 6s - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0223 - val_accuracy: 0.9950\n",
            "Epoch 93/400\n",
            "52/52 - 6s - loss: 0.0210 - accuracy: 0.9961 - val_loss: 0.0144 - val_accuracy: 0.9967\n",
            "Epoch 94/400\n",
            "52/52 - 6s - loss: 0.0216 - accuracy: 0.9956 - val_loss: 0.0173 - val_accuracy: 0.9950\n",
            "Epoch 95/400\n",
            "52/52 - 6s - loss: 0.0196 - accuracy: 0.9961 - val_loss: 0.0291 - val_accuracy: 0.9933\n",
            "Epoch 96/400\n",
            "52/52 - 6s - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.0181 - val_accuracy: 0.9950\n",
            "Epoch 97/400\n",
            "52/52 - 6s - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.0136 - val_accuracy: 0.9967\n",
            "Epoch 98/400\n",
            "52/52 - 6s - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0165 - val_accuracy: 0.9950\n",
            "Epoch 99/400\n",
            "52/52 - 6s - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.0130 - val_accuracy: 0.9967\n",
            "Epoch 100/400\n",
            "52/52 - 6s - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.0127 - val_accuracy: 0.9967\n",
            "Epoch 101/400\n",
            "52/52 - 6s - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.0245 - val_accuracy: 0.9942\n",
            "Epoch 102/400\n",
            "52/52 - 6s - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0130 - val_accuracy: 0.9983\n",
            "Epoch 103/400\n",
            "52/52 - 6s - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.0122 - val_accuracy: 0.9967\n",
            "Epoch 104/400\n",
            "52/52 - 6s - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0129 - val_accuracy: 0.9975\n",
            "Epoch 105/400\n",
            "52/52 - 6s - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.0117 - val_accuracy: 0.9967\n",
            "Epoch 106/400\n",
            "52/52 - 6s - loss: 0.0175 - accuracy: 0.9967 - val_loss: 0.0121 - val_accuracy: 0.9967\n",
            "Epoch 107/400\n",
            "52/52 - 6s - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0145 - val_accuracy: 0.9967\n",
            "Epoch 108/400\n",
            "52/52 - 6s - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.0314 - val_accuracy: 0.9908\n",
            "Epoch 109/400\n",
            "52/52 - 6s - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.0190 - val_accuracy: 0.9942\n",
            "Epoch 110/400\n",
            "52/52 - 6s - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.0126 - val_accuracy: 0.9975\n",
            "Epoch 111/400\n",
            "52/52 - 6s - loss: 0.0145 - accuracy: 0.9961 - val_loss: 0.0111 - val_accuracy: 0.9967\n",
            "Epoch 112/400\n",
            "52/52 - 6s - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0109 - val_accuracy: 0.9983\n",
            "Epoch 113/400\n",
            "52/52 - 6s - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0138 - val_accuracy: 0.9967\n",
            "Epoch 114/400\n",
            "52/52 - 6s - loss: 0.0146 - accuracy: 0.9967 - val_loss: 0.0340 - val_accuracy: 0.9892\n",
            "Epoch 115/400\n",
            "52/52 - 6s - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0135 - val_accuracy: 0.9967\n",
            "Epoch 116/400\n",
            "52/52 - 6s - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0107 - val_accuracy: 0.9967\n",
            "Epoch 117/400\n",
            "52/52 - 6s - loss: 0.0118 - accuracy: 0.9975 - val_loss: 0.0129 - val_accuracy: 0.9975\n",
            "Epoch 118/400\n",
            "52/52 - 6s - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0101 - val_accuracy: 0.9967\n",
            "Epoch 119/400\n",
            "52/52 - 6s - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.0151 - val_accuracy: 0.9967\n",
            "Epoch 120/400\n",
            "52/52 - 6s - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.0103 - val_accuracy: 0.9983\n",
            "Epoch 121/400\n",
            "52/52 - 6s - loss: 0.0111 - accuracy: 0.9981 - val_loss: 0.0106 - val_accuracy: 0.9975\n",
            "Epoch 122/400\n",
            "52/52 - 6s - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0140 - val_accuracy: 0.9967\n",
            "Epoch 123/400\n",
            "52/52 - 6s - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.0103 - val_accuracy: 0.9983\n",
            "Epoch 124/400\n",
            "52/52 - 6s - loss: 0.0133 - accuracy: 0.9967 - val_loss: 0.0096 - val_accuracy: 0.9983\n",
            "Epoch 125/400\n",
            "52/52 - 6s - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.0107 - val_accuracy: 0.9983\n",
            "Epoch 126/400\n",
            "52/52 - 6s - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.0093 - val_accuracy: 0.9983\n",
            "Epoch 127/400\n",
            "52/52 - 6s - loss: 0.0100 - accuracy: 0.9975 - val_loss: 0.0100 - val_accuracy: 0.9975\n",
            "Epoch 128/400\n",
            "52/52 - 6s - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.0152 - val_accuracy: 0.9967\n",
            "Epoch 129/400\n",
            "52/52 - 6s - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.0101 - val_accuracy: 0.9975\n",
            "Epoch 130/400\n",
            "52/52 - 6s - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.0095 - val_accuracy: 0.9983\n",
            "Epoch 131/400\n",
            "52/52 - 6s - loss: 0.0223 - accuracy: 0.9953 - val_loss: 0.0167 - val_accuracy: 0.9950\n",
            "Epoch 132/400\n",
            "52/52 - 6s - loss: 0.0090 - accuracy: 0.9981 - val_loss: 0.0095 - val_accuracy: 0.9975\n",
            "Epoch 133/400\n",
            "52/52 - 6s - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.0100 - val_accuracy: 0.9983\n",
            "Epoch 134/400\n",
            "52/52 - 6s - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0085 - val_accuracy: 0.9983\n",
            "Epoch 135/400\n",
            "52/52 - 6s - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.0117 - val_accuracy: 0.9975\n",
            "Epoch 136/400\n",
            "52/52 - 6s - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0103 - val_accuracy: 0.9983\n",
            "Epoch 137/400\n",
            "52/52 - 6s - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.0081 - val_accuracy: 0.9983\n",
            "Epoch 138/400\n",
            "52/52 - 6s - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0101 - val_accuracy: 0.9983\n",
            "Epoch 139/400\n",
            "52/52 - 6s - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0083 - val_accuracy: 0.9992\n",
            "Epoch 140/400\n",
            "52/52 - 6s - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.0086 - val_accuracy: 0.9975\n",
            "Epoch 141/400\n",
            "52/52 - 6s - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0083 - val_accuracy: 0.9992\n",
            "Epoch 142/400\n",
            "52/52 - 6s - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.0081 - val_accuracy: 0.9975\n",
            "Epoch 143/400\n",
            "52/52 - 6s - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0087 - val_accuracy: 0.9983\n",
            "Epoch 144/400\n",
            "52/52 - 6s - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
            "Epoch 145/400\n",
            "52/52 - 6s - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.0078 - val_accuracy: 0.9992\n",
            "Epoch 146/400\n",
            "52/52 - 6s - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0082 - val_accuracy: 0.9992\n",
            "Epoch 147/400\n",
            "52/52 - 6s - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.0095 - val_accuracy: 0.9975\n",
            "Epoch 148/400\n",
            "52/52 - 6s - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0094 - val_accuracy: 0.9983\n",
            "Epoch 149/400\n",
            "52/52 - 6s - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0076 - val_accuracy: 0.9992\n",
            "Epoch 150/400\n",
            "52/52 - 6s - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0098 - val_accuracy: 0.9975\n",
            "Epoch 151/400\n",
            "52/52 - 6s - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.0079 - val_accuracy: 0.9992\n",
            "Epoch 152/400\n",
            "52/52 - 6s - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0075 - val_accuracy: 0.9975\n",
            "Epoch 153/400\n",
            "52/52 - 6s - loss: 0.0093 - accuracy: 0.9981 - val_loss: 0.0167 - val_accuracy: 0.9958\n",
            "Epoch 154/400\n",
            "52/52 - 6s - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.0081 - val_accuracy: 0.9983\n",
            "Epoch 155/400\n",
            "52/52 - 6s - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.0084 - val_accuracy: 0.9983\n",
            "Epoch 156/400\n",
            "52/52 - 6s - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0110 - val_accuracy: 0.9967\n",
            "Epoch 157/400\n",
            "52/52 - 6s - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0077 - val_accuracy: 0.9992\n",
            "Epoch 158/400\n",
            "52/52 - 6s - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
            "Epoch 159/400\n",
            "52/52 - 6s - loss: 0.0083 - accuracy: 0.9967 - val_loss: 0.0094 - val_accuracy: 0.9975\n",
            "Epoch 160/400\n",
            "52/52 - 6s - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0072 - val_accuracy: 0.9975\n",
            "Epoch 161/400\n",
            "52/52 - 6s - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
            "Epoch 162/400\n",
            "52/52 - 6s - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0072 - val_accuracy: 0.9975\n",
            "Epoch 163/400\n",
            "52/52 - 6s - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0076 - val_accuracy: 0.9992\n",
            "Epoch 164/400\n",
            "52/52 - 6s - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
            "Epoch 165/400\n",
            "52/52 - 6s - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
            "Epoch 166/400\n",
            "52/52 - 6s - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0093 - val_accuracy: 0.9967\n",
            "Epoch 167/400\n",
            "52/52 - 6s - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0104 - val_accuracy: 0.9975\n",
            "Epoch 168/400\n",
            "52/52 - 6s - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0079 - val_accuracy: 0.9992\n",
            "Epoch 169/400\n",
            "52/52 - 6s - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
            "Epoch 170/400\n",
            "52/52 - 6s - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
            "Epoch 171/400\n",
            "52/52 - 6s - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0071 - val_accuracy: 0.9975\n",
            "Epoch 172/400\n",
            "52/52 - 6s - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
            "Epoch 173/400\n",
            "52/52 - 6s - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0088 - val_accuracy: 0.9983\n",
            "Epoch 174/400\n",
            "52/52 - 6s - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0099 - val_accuracy: 0.9950\n",
            "Epoch 175/400\n",
            "52/52 - 6s - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0066 - val_accuracy: 0.9992\n",
            "Epoch 176/400\n",
            "52/52 - 6s - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0098 - val_accuracy: 0.9975\n",
            "Epoch 177/400\n",
            "52/52 - 6s - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
            "Epoch 178/400\n",
            "52/52 - 6s - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0075 - val_accuracy: 0.9975\n",
            "Epoch 179/400\n",
            "52/52 - 6s - loss: 0.0033 - accuracy: 0.9986 - val_loss: 0.0081 - val_accuracy: 0.9992\n",
            "Epoch 180/400\n",
            "52/52 - 6s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 181/400\n",
            "52/52 - 6s - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0077 - val_accuracy: 0.9992\n",
            "Epoch 182/400\n",
            "52/52 - 6s - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0068 - val_accuracy: 0.9992\n",
            "Epoch 183/400\n",
            "52/52 - 6s - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0067 - val_accuracy: 0.9992\n",
            "Epoch 184/400\n",
            "52/52 - 6s - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0068 - val_accuracy: 0.9975\n",
            "Epoch 185/400\n",
            "52/52 - 6s - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0093 - val_accuracy: 0.9975\n",
            "Epoch 186/400\n",
            "52/52 - 6s - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0077 - val_accuracy: 0.9992\n",
            "Epoch 187/400\n",
            "52/52 - 6s - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0066 - val_accuracy: 0.9992\n",
            "Epoch 188/400\n",
            "52/52 - 6s - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0064 - val_accuracy: 0.9983\n",
            "Epoch 189/400\n",
            "52/52 - 6s - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0087 - val_accuracy: 0.9967\n",
            "Epoch 190/400\n",
            "52/52 - 6s - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
            "Epoch 191/400\n",
            "52/52 - 6s - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 192/400\n",
            "52/52 - 6s - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0089 - val_accuracy: 0.9983\n",
            "Epoch 193/400\n",
            "52/52 - 6s - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 194/400\n",
            "52/52 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 195/400\n",
            "52/52 - 6s - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 196/400\n",
            "52/52 - 6s - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 197/400\n",
            "52/52 - 6s - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 198/400\n",
            "52/52 - 6s - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0089 - val_accuracy: 0.9967\n",
            "Epoch 199/400\n",
            "52/52 - 6s - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 200/400\n",
            "52/52 - 6s - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 201/400\n",
            "52/52 - 6s - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0096 - val_accuracy: 0.9983\n",
            "Epoch 202/400\n",
            "52/52 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 203/400\n",
            "52/52 - 6s - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9975\n",
            "Epoch 204/400\n",
            "52/52 - 6s - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 205/400\n",
            "52/52 - 6s - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 206/400\n",
            "52/52 - 6s - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0105 - val_accuracy: 0.9967\n",
            "Epoch 207/400\n",
            "52/52 - 6s - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 208/400\n",
            "52/52 - 6s - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9967\n",
            "Epoch 209/400\n",
            "52/52 - 6s - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 210/400\n",
            "52/52 - 6s - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0072 - val_accuracy: 0.9992\n",
            "Epoch 211/400\n",
            "52/52 - 6s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
            "Epoch 212/400\n",
            "52/52 - 6s - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
            "Epoch 213/400\n",
            "52/52 - 6s - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 214/400\n",
            "52/52 - 6s - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0076 - val_accuracy: 0.9992\n",
            "Epoch 215/400\n",
            "52/52 - 6s - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0090 - val_accuracy: 0.9950\n",
            "Epoch 216/400\n",
            "52/52 - 6s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 217/400\n",
            "52/52 - 6s - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0387 - val_accuracy: 0.9883\n",
            "Epoch 218/400\n",
            "52/52 - 6s - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 219/400\n",
            "52/52 - 6s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9992\n",
            "Epoch 220/400\n",
            "52/52 - 6s - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 221/400\n",
            "52/52 - 6s - loss: 0.0087 - accuracy: 0.9964 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
            "Epoch 222/400\n",
            "52/52 - 6s - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 223/400\n",
            "52/52 - 6s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9992\n",
            "Epoch 224/400\n",
            "52/52 - 6s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9992\n",
            "Epoch 225/400\n",
            "52/52 - 6s - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 226/400\n",
            "52/52 - 6s - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0057 - val_accuracy: 0.9992\n",
            "Epoch 227/400\n",
            "52/52 - 6s - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
            "Epoch 228/400\n",
            "52/52 - 6s - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 229/400\n",
            "52/52 - 6s - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 230/400\n",
            "52/52 - 6s - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 231/400\n",
            "52/52 - 6s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9992\n",
            "Epoch 232/400\n",
            "52/52 - 6s - loss: 8.9786e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
            "Epoch 233/400\n",
            "52/52 - 6s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 234/400\n",
            "52/52 - 6s - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0148 - val_accuracy: 0.9942\n",
            "Epoch 235/400\n",
            "52/52 - 6s - loss: 0.0032 - accuracy: 0.9986 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 236/400\n",
            "52/52 - 6s - loss: 8.4966e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 237/400\n",
            "52/52 - 6s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9992\n",
            "Epoch 238/400\n",
            "52/52 - 6s - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0077 - val_accuracy: 0.9992\n",
            "Epoch 239/400\n",
            "52/52 - 6s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 240/400\n",
            "52/52 - 6s - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.0074 - val_accuracy: 0.9992\n",
            "Epoch 241/400\n",
            "52/52 - 6s - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 242/400\n",
            "52/52 - 6s - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0066 - val_accuracy: 0.9992\n",
            "Epoch 243/400\n",
            "52/52 - 6s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9975\n",
            "Epoch 244/400\n",
            "52/52 - 6s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9967\n",
            "Epoch 245/400\n",
            "52/52 - 6s - loss: 8.6815e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 246/400\n",
            "52/52 - 6s - loss: 8.7351e-04 - accuracy: 0.9997 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 247/400\n",
            "52/52 - 6s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0088 - val_accuracy: 0.9967\n",
            "Epoch 248/400\n",
            "52/52 - 6s - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
            "Epoch 249/400\n",
            "52/52 - 6s - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0084 - val_accuracy: 0.9967\n",
            "Epoch 250/400\n",
            "52/52 - 6s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 251/400\n",
            "52/52 - 6s - loss: 5.7070e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 252/400\n",
            "52/52 - 6s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9992\n",
            "Epoch 253/400\n",
            "52/52 - 6s - loss: 7.2892e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9992\n",
            "Epoch 254/400\n",
            "52/52 - 6s - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
            "Epoch 255/400\n",
            "52/52 - 6s - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0055 - val_accuracy: 0.9992\n",
            "Epoch 256/400\n",
            "52/52 - 6s - loss: 6.8639e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 257/400\n",
            "52/52 - 6s - loss: 9.9528e-04 - accuracy: 0.9997 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
            "Epoch 258/400\n",
            "52/52 - 6s - loss: 9.7095e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 259/400\n",
            "52/52 - 6s - loss: 9.7597e-04 - accuracy: 0.9997 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 260/400\n",
            "52/52 - 6s - loss: 8.0920e-04 - accuracy: 0.9997 - val_loss: 0.0093 - val_accuracy: 0.9958\n",
            "Epoch 261/400\n",
            "52/52 - 6s - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 262/400\n",
            "52/52 - 6s - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0528 - val_accuracy: 0.9842\n",
            "Epoch 263/400\n",
            "52/52 - 6s - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 264/400\n",
            "52/52 - 6s - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 0.9967\n",
            "Epoch 265/400\n",
            "52/52 - 6s - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0053 - val_accuracy: 0.9992\n",
            "Epoch 266/400\n",
            "52/52 - 6s - loss: 5.8503e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 267/400\n",
            "52/52 - 6s - loss: 7.1740e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9992\n",
            "Epoch 268/400\n",
            "52/52 - 6s - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0380 - val_accuracy: 0.9883\n",
            "Epoch 269/400\n",
            "52/52 - 6s - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.0055 - val_accuracy: 0.9992\n",
            "Epoch 270/400\n",
            "52/52 - 6s - loss: 8.3500e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 271/400\n",
            "52/52 - 6s - loss: 9.8984e-04 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 0.9992\n",
            "Epoch 272/400\n",
            "52/52 - 6s - loss: 8.1324e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 273/400\n",
            "52/52 - 6s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 274/400\n",
            "52/52 - 6s - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0079 - val_accuracy: 0.9992\n",
            "Epoch 275/400\n",
            "52/52 - 6s - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.0087 - val_accuracy: 0.9975\n",
            "Epoch 276/400\n",
            "52/52 - 6s - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9983\n",
            "Epoch 277/400\n",
            "52/52 - 6s - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0045 - val_accuracy: 0.9983\n",
            "Epoch 278/400\n",
            "52/52 - 6s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 279/400\n",
            "52/52 - 6s - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
            "Epoch 280/400\n",
            "52/52 - 6s - loss: 9.8007e-04 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
            "Epoch 281/400\n",
            "52/52 - 6s - loss: 9.8689e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9992\n",
            "Epoch 282/400\n",
            "52/52 - 6s - loss: 7.5614e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
            "Epoch 283/400\n",
            "52/52 - 6s - loss: 6.5107e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
            "Epoch 284/400\n",
            "52/52 - 6s - loss: 9.4617e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
            "Epoch 285/400\n",
            "52/52 - 6s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9992\n",
            "Epoch 286/400\n",
            "52/52 - 6s - loss: 6.7491e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
            "Epoch 287/400\n",
            "52/52 - 6s - loss: 8.9575e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9992\n",
            "Epoch 288/400\n",
            "52/52 - 6s - loss: 5.8553e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
            "Epoch 289/400\n",
            "52/52 - 6s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 290/400\n",
            "52/52 - 6s - loss: 6.2158e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 291/400\n",
            "52/52 - 6s - loss: 4.2255e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9992\n",
            "Epoch 292/400\n",
            "52/52 - 6s - loss: 9.1890e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 293/400\n",
            "52/52 - 6s - loss: 4.5654e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 294/400\n",
            "52/52 - 6s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0057 - val_accuracy: 0.9992\n",
            "Epoch 295/400\n",
            "52/52 - 6s - loss: 5.1008e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 296/400\n",
            "52/52 - 6s - loss: 0.0030 - accuracy: 0.9986 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
            "Epoch 297/400\n",
            "52/52 - 6s - loss: 5.7817e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 298/400\n",
            "52/52 - 6s - loss: 9.7938e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 299/400\n",
            "52/52 - 6s - loss: 7.4773e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9992\n",
            "Epoch 300/400\n",
            "52/52 - 6s - loss: 4.4187e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 301/400\n",
            "52/52 - 6s - loss: 6.9922e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9975\n",
            "Epoch 302/400\n",
            "52/52 - 6s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 303/400\n",
            "52/52 - 6s - loss: 4.6358e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 304/400\n",
            "52/52 - 6s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9992\n",
            "Epoch 305/400\n",
            "52/52 - 6s - loss: 3.9262e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 306/400\n",
            "52/52 - 6s - loss: 7.5471e-04 - accuracy: 0.9997 - val_loss: 0.0132 - val_accuracy: 0.9975\n",
            "Epoch 307/400\n",
            "52/52 - 6s - loss: 0.0097 - accuracy: 0.9961 - val_loss: 0.0049 - val_accuracy: 0.9983\n",
            "Epoch 308/400\n",
            "52/52 - 6s - loss: 7.4819e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9983\n",
            "Epoch 309/400\n",
            "52/52 - 6s - loss: 5.8564e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 310/400\n",
            "52/52 - 6s - loss: 4.7814e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 311/400\n",
            "52/52 - 6s - loss: 3.1336e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 312/400\n",
            "52/52 - 6s - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0343 - val_accuracy: 0.9917\n",
            "Epoch 313/400\n",
            "52/52 - 6s - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 314/400\n",
            "52/52 - 6s - loss: 6.3965e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 315/400\n",
            "52/52 - 6s - loss: 3.8848e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 316/400\n",
            "52/52 - 6s - loss: 6.3594e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9992\n",
            "Epoch 317/400\n",
            "52/52 - 6s - loss: 5.9556e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 318/400\n",
            "52/52 - 6s - loss: 3.0355e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9992\n",
            "Epoch 319/400\n",
            "52/52 - 6s - loss: 4.5588e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9992\n",
            "Epoch 320/400\n",
            "52/52 - 6s - loss: 3.6338e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 321/400\n",
            "52/52 - 6s - loss: 7.5419e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 322/400\n",
            "52/52 - 6s - loss: 2.8661e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
            "Epoch 323/400\n",
            "52/52 - 6s - loss: 2.7596e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 324/400\n",
            "52/52 - 6s - loss: 3.4352e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
            "Epoch 325/400\n",
            "52/52 - 6s - loss: 5.8427e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 326/400\n",
            "52/52 - 6s - loss: 2.3355e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 327/400\n",
            "52/52 - 6s - loss: 4.6800e-04 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9992\n",
            "Epoch 328/400\n",
            "52/52 - 6s - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0093 - val_accuracy: 0.9983\n",
            "Epoch 329/400\n",
            "52/52 - 6s - loss: 5.7496e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9983\n",
            "Epoch 330/400\n",
            "52/52 - 6s - loss: 8.4043e-04 - accuracy: 0.9997 - val_loss: 0.0053 - val_accuracy: 0.9983\n",
            "Epoch 331/400\n",
            "52/52 - 6s - loss: 4.5517e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 332/400\n",
            "52/52 - 6s - loss: 8.1962e-04 - accuracy: 0.9997 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 333/400\n",
            "52/52 - 6s - loss: 6.1775e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
            "Epoch 334/400\n",
            "52/52 - 6s - loss: 5.7189e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
            "Epoch 335/400\n",
            "52/52 - 6s - loss: 2.4998e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 336/400\n",
            "52/52 - 6s - loss: 7.4243e-04 - accuracy: 0.9997 - val_loss: 0.0087 - val_accuracy: 0.9992\n",
            "Epoch 337/400\n",
            "52/52 - 6s - loss: 7.3714e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 338/400\n",
            "52/52 - 6s - loss: 5.3639e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 339/400\n",
            "52/52 - 6s - loss: 2.5564e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 340/400\n",
            "52/52 - 6s - loss: 3.3587e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
            "Epoch 341/400\n",
            "52/52 - 6s - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0359 - val_accuracy: 0.9933\n",
            "Epoch 342/400\n",
            "52/52 - 6s - loss: 0.0178 - accuracy: 0.9925 - val_loss: 0.0046 - val_accuracy: 0.9975\n",
            "Epoch 343/400\n",
            "52/52 - 6s - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
            "Epoch 344/400\n",
            "52/52 - 6s - loss: 8.2509e-04 - accuracy: 0.9997 - val_loss: 0.0052 - val_accuracy: 0.9992\n",
            "Epoch 345/400\n",
            "52/52 - 6s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
            "Epoch 346/400\n",
            "52/52 - 6s - loss: 9.9330e-04 - accuracy: 0.9997 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
            "Epoch 347/400\n",
            "52/52 - 6s - loss: 4.5443e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 348/400\n",
            "52/52 - 6s - loss: 2.8129e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 349/400\n",
            "52/52 - 6s - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.0054 - val_accuracy: 0.9992\n",
            "Epoch 350/400\n",
            "52/52 - 6s - loss: 5.7741e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 351/400\n",
            "52/52 - 6s - loss: 5.4033e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 352/400\n",
            "52/52 - 6s - loss: 2.3109e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9992\n",
            "Epoch 353/400\n",
            "52/52 - 6s - loss: 8.2013e-04 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 0.9992\n",
            "Epoch 354/400\n",
            "52/52 - 6s - loss: 3.7527e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
            "Epoch 355/400\n",
            "52/52 - 6s - loss: 3.4434e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
            "Epoch 356/400\n",
            "52/52 - 6s - loss: 2.6030e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 357/400\n",
            "52/52 - 6s - loss: 1.5227e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
            "Epoch 358/400\n",
            "52/52 - 6s - loss: 3.4138e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9992\n",
            "Epoch 359/400\n",
            "52/52 - 6s - loss: 4.7104e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 360/400\n",
            "52/52 - 6s - loss: 4.7135e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9992\n",
            "Epoch 361/400\n",
            "52/52 - 6s - loss: 4.1484e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
            "Epoch 362/400\n",
            "52/52 - 6s - loss: 6.9075e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 363/400\n",
            "52/52 - 6s - loss: 3.7569e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 364/400\n",
            "52/52 - 6s - loss: 5.3333e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 365/400\n",
            "52/52 - 6s - loss: 2.3745e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
            "Epoch 366/400\n",
            "52/52 - 6s - loss: 2.3712e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9992\n",
            "Epoch 367/400\n",
            "52/52 - 6s - loss: 2.8963e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9992\n",
            "Epoch 368/400\n",
            "52/52 - 6s - loss: 0.0078 - accuracy: 0.9967 - val_loss: 0.0049 - val_accuracy: 0.9983\n",
            "Epoch 369/400\n",
            "52/52 - 6s - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
            "Epoch 370/400\n",
            "52/52 - 6s - loss: 3.6566e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 371/400\n",
            "52/52 - 6s - loss: 7.9092e-04 - accuracy: 0.9997 - val_loss: 0.0078 - val_accuracy: 0.9992\n",
            "Epoch 372/400\n",
            "52/52 - 6s - loss: 5.6061e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 373/400\n",
            "52/52 - 6s - loss: 4.0362e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 374/400\n",
            "52/52 - 6s - loss: 1.1621e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
            "Epoch 375/400\n",
            "52/52 - 6s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
            "Epoch 376/400\n",
            "52/52 - 6s - loss: 4.4414e-04 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 377/400\n",
            "52/52 - 6s - loss: 4.6790e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9992\n",
            "Epoch 378/400\n",
            "52/52 - 6s - loss: 2.8483e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 379/400\n",
            "52/52 - 6s - loss: 1.3971e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 380/400\n",
            "52/52 - 6s - loss: 1.3151e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9992\n",
            "Epoch 381/400\n",
            "52/52 - 6s - loss: 6.1188e-04 - accuracy: 0.9997 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
            "Epoch 382/400\n",
            "52/52 - 6s - loss: 6.4057e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 383/400\n",
            "52/52 - 6s - loss: 3.6722e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 384/400\n",
            "52/52 - 6s - loss: 1.6492e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 385/400\n",
            "52/52 - 6s - loss: 1.4676e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 386/400\n",
            "52/52 - 6s - loss: 1.4492e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9992\n",
            "Epoch 387/400\n",
            "52/52 - 6s - loss: 4.5169e-04 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9992\n",
            "Epoch 388/400\n",
            "52/52 - 6s - loss: 2.8855e-04 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9992\n",
            "Epoch 389/400\n",
            "52/52 - 6s - loss: 0.0046 - accuracy: 0.9981 - val_loss: 0.0251 - val_accuracy: 0.9950\n",
            "Epoch 390/400\n",
            "52/52 - 6s - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
            "Epoch 391/400\n",
            "52/52 - 6s - loss: 3.5512e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9992\n",
            "Epoch 392/400\n",
            "52/52 - 6s - loss: 3.9624e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
            "Epoch 393/400\n",
            "52/52 - 6s - loss: 1.7749e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9992\n",
            "Epoch 394/400\n",
            "52/52 - 6s - loss: 3.9006e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 395/400\n",
            "52/52 - 6s - loss: 1.9763e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 396/400\n",
            "52/52 - 6s - loss: 1.8643e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
            "Epoch 397/400\n",
            "52/52 - 6s - loss: 6.4495e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
            "Epoch 398/400\n",
            "52/52 - 6s - loss: 2.0792e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "Epoch 399/400\n",
            "52/52 - 6s - loss: 1.4375e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9992\n",
            "Epoch 400/400\n",
            "52/52 - 6s - loss: 1.8226e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
            "{'loss': [0.7104341387748718, 0.5815750360488892, 0.45997175574302673, 0.3561306893825531, 0.3068702518939972, 0.2765701711177826, 0.2628156840801239, 0.25807762145996094, 0.25255346298217773, 0.24934740364551544, 0.2495821863412857, 0.24600909650325775, 0.246434286236763, 0.23767973482608795, 0.24136759340763092, 0.23540017008781433, 0.24288970232009888, 0.2295517474412918, 0.22852976620197296, 0.22896087169647217, 0.22620707750320435, 0.2290632277727127, 0.2307584285736084, 0.22113266587257385, 0.21676208078861237, 0.21259792149066925, 0.20833267271518707, 0.20768974721431732, 0.20315277576446533, 0.2058681696653366, 0.19224584102630615, 0.19327813386917114, 0.18944215774536133, 0.18429109454154968, 0.17871326208114624, 0.1701679825782776, 0.16855841875076294, 0.16042037308216095, 0.15997031331062317, 0.1462208330631256, 0.13908907771110535, 0.13390697538852692, 0.1283901333808899, 0.12110260874032974, 0.11487729102373123, 0.10391548275947571, 0.10363101214170456, 0.0970078855752945, 0.08903056383132935, 0.08306867629289627, 0.0818815752863884, 0.07960827648639679, 0.07126133888959885, 0.07148421555757523, 0.06313133984804153, 0.06215181201696396, 0.05841986462473869, 0.05872519314289093, 0.05373930186033249, 0.05024869367480278, 0.05533242225646973, 0.054492976516485214, 0.052476391196250916, 0.04224538058042526, 0.04123636707663536, 0.04317634180188179, 0.0413181371986866, 0.03784077242016792, 0.045073267072439194, 0.03413109481334686, 0.03673270344734192, 0.03260764107108116, 0.03266818821430206, 0.030002865940332413, 0.033045943826436996, 0.030396949499845505, 0.03606123477220535, 0.029040439054369926, 0.028635242953896523, 0.02660430781543255, 0.027321934700012207, 0.035362809896469116, 0.028986049816012383, 0.02472129836678505, 0.02572479099035263, 0.025205247104167938, 0.022660713642835617, 0.025575311854481697, 0.022984057664871216, 0.022961292415857315, 0.02960459515452385, 0.02138577774167061, 0.021004704758524895, 0.02155853621661663, 0.019562287256121635, 0.02414146065711975, 0.021165966987609863, 0.020781535655260086, 0.020158395171165466, 0.016283107921481133, 0.021453220397233963, 0.01884623058140278, 0.01929575949907303, 0.014283058233559132, 0.01623285748064518, 0.01745547354221344, 0.01276880782097578, 0.015220736153423786, 0.01647772081196308, 0.013212095014750957, 0.014549910090863705, 0.011871992610394955, 0.012007031589746475, 0.014567635022103786, 0.016172561794519424, 0.011230668053030968, 0.01179088931530714, 0.011593775823712349, 0.015440140850841999, 0.014918099157512188, 0.01108100451529026, 0.011418141424655914, 0.01351749338209629, 0.013308475725352764, 0.013242816552519798, 0.009230367839336395, 0.010010787285864353, 0.009850794449448586, 0.011787457391619682, 0.010315212421119213, 0.022346220910549164, 0.008968045935034752, 0.010729392059147358, 0.009040212258696556, 0.007788625080138445, 0.01069003064185381, 0.006896506529301405, 0.010844322852790356, 0.016135072335600853, 0.009080780670046806, 0.006895038764923811, 0.00840088166296482, 0.007022895384579897, 0.007506486959755421, 0.007728668861091137, 0.007112027611583471, 0.008263746276497841, 0.005798438563942909, 0.006009448319673538, 0.005232773721218109, 0.009132598526775837, 0.007837713696062565, 0.009349938482046127, 0.00739956833422184, 0.009177646599709988, 0.004664095584303141, 0.006531377322971821, 0.0038444087840616703, 0.008316782303154469, 0.0033922751899808645, 0.0062429774552583694, 0.006910297553986311, 0.013598614372313023, 0.006474602967500687, 0.003615894354879856, 0.004319536034017801, 0.006016128230839968, 0.003292706562206149, 0.004921674728393555, 0.006579898763448, 0.005514163989573717, 0.006991844158619642, 0.005362669937312603, 0.009733401238918304, 0.0047688730992376804, 0.005336315371096134, 0.005521900486201048, 0.002550465054810047, 0.0032544690184295177, 0.002273522550240159, 0.002482403302565217, 0.0038270808290690184, 0.004046630579978228, 0.002813814440742135, 0.003991289995610714, 0.0038417025934904814, 0.010437059216201305, 0.007883388549089432, 0.0035548193845897913, 0.015943316742777824, 0.005901682656258345, 0.00496603874489665, 0.004538234788924456, 0.0018867228645831347, 0.00564091932028532, 0.002465993631631136, 0.00235794298350811, 0.0029030092991888523, 0.002247000578790903, 0.001959347166121006, 0.002465493744239211, 0.0020327235106378794, 0.001777805620804429, 0.002932362025603652, 0.0013589950976893306, 0.006413704250007868, 0.005217001773416996, 0.0019443938508629799, 0.003296796465292573, 0.0036284129600971937, 0.0015093795955181122, 0.004623366054147482, 0.0018968310905620456, 0.0023398781195282936, 0.011085745878517628, 0.002030398230999708, 0.004642794840037823, 0.006193196401000023, 0.0015268726274371147, 0.0018263543024659157, 0.00872104149311781, 0.003688584081828594, 0.0013587215216830373, 0.001646737102419138, 0.001373736304230988, 0.0021765681449323893, 0.003085872158408165, 0.002217208966612816, 0.0016681804554536939, 0.00288810720667243, 0.0011514687212184072, 0.0008978607947938144, 0.0010656133526936173, 0.0019429316744208336, 0.003188531845808029, 0.000849658390507102, 0.001061323331668973, 0.005896538496017456, 0.0013786435592919588, 0.004897939041256905, 0.0024277593474835157, 0.0022668715100735426, 0.00170314300339669, 0.0020600659772753716, 0.0008681538165546954, 0.000873507116921246, 0.0013001881306990981, 0.0014117284445092082, 0.006751571781933308, 0.0016427678056061268, 0.000570699863601476, 0.001061933464370668, 0.0007289221975952387, 0.005190750118345022, 0.0025260066613554955, 0.0006863939925096929, 0.0009952784748747945, 0.0009709498845040798, 0.0009759746608324349, 0.0008092027273960412, 0.0013817286817356944, 0.004729120992124081, 0.003212164156138897, 0.0010093237506225705, 0.0015141047770157456, 0.0005850275629200041, 0.0007174049969762564, 0.002115437760949135, 0.004863222595304251, 0.0008349994895979762, 0.0009898414136841893, 0.0008132365182973444, 0.00112595921382308, 0.002229694277048111, 0.039309900254011154, 0.003433571895584464, 0.002081314567476511, 0.0010035651503130794, 0.002548689255490899, 0.0009800686966627836, 0.0009868878405541182, 0.0007561425445601344, 0.0006510688690468669, 0.0009461685549467802, 0.0010133824544027448, 0.0006749056628905237, 0.0008957465761341155, 0.0005855250637978315, 0.0011075695510953665, 0.0006215812754817307, 0.0004225452139507979, 0.0009189012926071882, 0.00045653909910470247, 0.001070988248102367, 0.0005100846756249666, 0.0029831454157829285, 0.0005781716899946332, 0.0009793795179575682, 0.0007477309554815292, 0.00044186669401824474, 0.0006992166745476425, 0.0010507541010156274, 0.00046358065446838737, 0.0011296399170532823, 0.0003926182398572564, 0.0007547130226157606, 0.009656704030930996, 0.0007481874199584126, 0.0005856407224200666, 0.00047814188292250037, 0.0003133627469651401, 0.003320809453725815, 0.002419987227767706, 0.0006396489916369319, 0.00038848345866426826, 0.0006359447143040597, 0.0005955550586804748, 0.0003035461122635752, 0.0004558812943287194, 0.00036338201607577503, 0.0007541899685747921, 0.000286607799353078, 0.00027596059953793883, 0.0003435193793848157, 0.0005842726677656174, 0.0002335485623916611, 0.00046800082782283425, 0.0018990780226886272, 0.0005749601987190545, 0.0008404296822845936, 0.00045517185935750604, 0.0008196249254979193, 0.0006177474861033261, 0.0005718943430110812, 0.0002499754191376269, 0.0007424330106005073, 0.0007371374522335827, 0.0005363853415474296, 0.00025564132374711335, 0.00033586545032449067, 0.005117096938192844, 0.01778838410973549, 0.003827218897640705, 0.0008250898099504411, 0.001101984060369432, 0.0009933019755408168, 0.0004544306721072644, 0.00028129012207500637, 0.001126988441683352, 0.0005774099263362586, 0.0005403286195360124, 0.00023109381436370313, 0.000820126268081367, 0.00037527011591009796, 0.00034434322151355445, 0.0002603017201181501, 0.0001522695238236338, 0.00034137628972530365, 0.0004710395587608218, 0.0004713489324785769, 0.0004148437292315066, 0.0006907490896992385, 0.00037569127744063735, 0.0005333250155672431, 0.00023745086218696088, 0.00023711701214779168, 0.00028962994110770524, 0.007847806438803673, 0.0025890565011650324, 0.00036566334892995656, 0.0007909233099780977, 0.0005606053164228797, 0.00040361908031627536, 0.00011621105659287423, 0.0011211163364350796, 0.00044413970317691565, 0.0004679040575865656, 0.0002848260337486863, 0.0001397055748384446, 0.00013150976155884564, 0.0006118844612501562, 0.000640574493445456, 0.00036721632932312787, 0.00016492132272105664, 0.00014675752026960254, 0.0001449176634196192, 0.0004516873450484127, 0.00028854867559857666, 0.004591300152242184, 0.00932607427239418, 0.00035511841997504234, 0.0003962408227380365, 0.00017748703248798847, 0.0003900579467881471, 0.0001976271450985223, 0.00018643177463673055, 0.0006449496722780168, 0.00020792170835193247, 0.00014374707825481892, 0.000182258416316472], 'accuracy': [0.5525000095367432, 0.7275000214576721, 0.8188889026641846, 0.867222249507904, 0.8799999952316284, 0.8913888931274414, 0.8941666483879089, 0.8899999856948853, 0.8947222232818604, 0.897777795791626, 0.8994444608688354, 0.8963888883590698, 0.8955555558204651, 0.8980555534362793, 0.8963888883590698, 0.9030555486679077, 0.8930555582046509, 0.9058333039283752, 0.9058333039283752, 0.9058333039283752, 0.902222216129303, 0.9002777934074402, 0.9024999737739563, 0.9077777862548828, 0.9069444537162781, 0.9088888764381409, 0.9113888740539551, 0.9141666889190674, 0.9144444465637207, 0.9144444465637207, 0.9188888669013977, 0.9175000190734863, 0.9191666841506958, 0.9222221970558167, 0.926111102104187, 0.9247221946716309, 0.9275000095367432, 0.9291666746139526, 0.9322222471237183, 0.9383333325386047, 0.9411110877990723, 0.9469444155693054, 0.945555567741394, 0.9513888955116272, 0.9541666507720947, 0.9580555558204651, 0.9608333110809326, 0.9655555486679077, 0.9661111235618591, 0.9736111164093018, 0.9736111164093018, 0.9719444513320923, 0.9780555367469788, 0.9763888716697693, 0.9827777743339539, 0.9822221994400024, 0.9825000166893005, 0.9844444394111633, 0.9850000143051147, 0.9877777695655823, 0.9863888621330261, 0.9852777719497681, 0.9844444394111633, 0.9897222518920898, 0.9897222518920898, 0.9891666769981384, 0.9894444346427917, 0.9888888597488403, 0.9883333444595337, 0.992222249507904, 0.9913889169692993, 0.9913889169692993, 0.991944432258606, 0.9927777647972107, 0.9913889169692993, 0.9936110973358154, 0.988611102104187, 0.992222249507904, 0.9913889169692993, 0.9938889145851135, 0.9927777647972107, 0.991944432258606, 0.992222249507904, 0.9938889145851135, 0.9927777647972107, 0.9930555820465088, 0.9944444298744202, 0.9941666722297668, 0.9938889145851135, 0.9936110973358154, 0.9916666746139526, 0.9933333396911621, 0.9961110949516296, 0.995555579662323, 0.9961110949516296, 0.9936110973358154, 0.9941666722297668, 0.9933333396911621, 0.9938889145851135, 0.9958333373069763, 0.9938889145851135, 0.9936110973358154, 0.9947222471237183, 0.9958333373069763, 0.9969444274902344, 0.996666669845581, 0.9961110949516296, 0.9961110949516296, 0.9952777624130249, 0.9952777624130249, 0.9961110949516296, 0.9969444274902344, 0.9969444274902344, 0.996666669845581, 0.9947222471237183, 0.9969444274902344, 0.9975000023841858, 0.9969444274902344, 0.9952777624130249, 0.9958333373069763, 0.9980555772781372, 0.9969444274902344, 0.9963889122009277, 0.996666669845581, 0.9963889122009277, 0.9972222447395325, 0.9975000023841858, 0.9975000023841858, 0.9958333373069763, 0.9975000023841858, 0.9952777624130249, 0.9980555772781372, 0.9975000023841858, 0.9969444274902344, 0.9988889098167419, 0.9972222447395325, 0.9980555772781372, 0.9963889122009277, 0.995555579662323, 0.9983333349227905, 0.9986110925674438, 0.9980555772781372, 0.9980555772781372, 0.9986110925674438, 0.9977777600288391, 0.9977777600288391, 0.9980555772781372, 0.9986110925674438, 0.9980555772781372, 0.9986110925674438, 0.996666669845581, 0.9972222447395325, 0.9980555772781372, 0.9986110925674438, 0.9980555772781372, 0.9994444251060486, 0.9980555772781372, 0.9994444251060486, 0.996666669845581, 0.9997222423553467, 0.9980555772781372, 0.9975000023841858, 0.9961110949516296, 0.9980555772781372, 0.9991666674613953, 0.9991666674613953, 0.9980555772781372, 0.9994444251060486, 0.9991666674613953, 0.9972222447395325, 0.9983333349227905, 0.9983333349227905, 0.9988889098167419, 0.9969444274902344, 0.9994444251060486, 0.9986110925674438, 0.9983333349227905, 0.9994444251060486, 0.9986110925674438, 1.0, 0.9997222423553467, 0.9986110925674438, 0.9988889098167419, 0.9994444251060486, 0.9988889098167419, 0.9991666674613953, 0.9972222447395325, 0.9975000023841858, 0.9991666674613953, 0.9941666722297668, 0.9977777600288391, 0.9988889098167419, 0.9986110925674438, 1.0, 0.9986110925674438, 0.9991666674613953, 0.9997222423553467, 0.9991666674613953, 0.9997222423553467, 0.9994444251060486, 0.9991666674613953, 1.0, 0.9997222423553467, 0.9994444251060486, 0.9997222423553467, 0.9983333349227905, 0.9983333349227905, 0.9997222423553467, 0.9994444251060486, 0.9986110925674438, 1.0, 0.9983333349227905, 0.9997222423553467, 0.9997222423553467, 0.9963889122009277, 1.0, 0.9986110925674438, 0.9983333349227905, 1.0, 0.9997222423553467, 0.9963889122009277, 0.9994444251060486, 1.0, 1.0, 0.9997222423553467, 0.9994444251060486, 0.9997222423553467, 0.9997222423553467, 0.9994444251060486, 0.9991666674613953, 1.0, 1.0, 1.0, 0.9997222423553467, 0.9986110925674438, 1.0, 1.0, 0.9980555772781372, 1.0, 0.9980555772781372, 0.9994444251060486, 0.9994444251060486, 1.0, 1.0, 1.0, 0.9997222423553467, 0.9997222423553467, 0.9997222423553467, 0.9980555772781372, 0.9997222423553467, 1.0, 1.0, 1.0, 0.9980555772781372, 0.9994444251060486, 1.0, 0.9997222423553467, 1.0, 0.9997222423553467, 0.9997222423553467, 0.9997222423553467, 0.9986110925674438, 0.9991666674613953, 0.9997222423553467, 0.9997222423553467, 1.0, 1.0, 0.9994444251060486, 0.9980555772781372, 1.0, 0.9997222423553467, 1.0, 0.9997222423553467, 0.9994444251060486, 0.987500011920929, 0.9991666674613953, 0.9997222423553467, 1.0, 0.9991666674613953, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997222423553467, 1.0, 1.0, 1.0, 1.0, 0.9997222423553467, 1.0, 0.9986110925674438, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997222423553467, 0.9961110949516296, 1.0, 1.0, 1.0, 1.0, 0.9991666674613953, 0.9988889098167419, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9991666674613953, 1.0, 0.9997222423553467, 1.0, 0.9997222423553467, 1.0, 1.0, 1.0, 0.9997222423553467, 1.0, 1.0, 1.0, 1.0, 0.9980555772781372, 0.9925000071525574, 0.9988889098167419, 0.9997222423553467, 0.9997222423553467, 0.9997222423553467, 1.0, 1.0, 0.9994444251060486, 1.0, 1.0, 1.0, 0.9997222423553467, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996666669845581, 0.9994444251060486, 1.0, 0.9997222423553467, 1.0, 1.0, 1.0, 0.9997222423553467, 0.9997222423553467, 1.0, 1.0, 1.0, 1.0, 0.9997222423553467, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9980555772781372, 0.996666669845581, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.6088777780532837, 0.4895505905151367, 0.3439214527606964, 0.274174302816391, 0.23609070479869843, 0.2190457135438919, 0.2170623540878296, 0.20689542591571808, 0.20590128004550934, 0.20301516354084015, 0.2028920203447342, 0.20169423520565033, 0.20476284623146057, 0.2007512003183365, 0.1962668001651764, 0.19536341726779938, 0.19386863708496094, 0.19061800837516785, 0.1944342851638794, 0.2030973732471466, 0.18603520095348358, 0.20355859398841858, 0.19262851774692535, 0.1879655420780182, 0.1795174777507782, 0.18042048811912537, 0.17390334606170654, 0.1707504242658615, 0.17050768435001373, 0.16491638123989105, 0.1666117161512375, 0.1620962768793106, 0.15320393443107605, 0.16790220141410828, 0.14196541905403137, 0.1386604905128479, 0.13418015837669373, 0.15159788727760315, 0.12031163275241852, 0.114266037940979, 0.1069067120552063, 0.1034388318657875, 0.09910145401954651, 0.09553047269582748, 0.08503512293100357, 0.07879788428544998, 0.07366766035556793, 0.07328876107931137, 0.06741894781589508, 0.06916462630033493, 0.05656055361032486, 0.053598932921886444, 0.05738253891468048, 0.04732543230056763, 0.04657274857163429, 0.041581328958272934, 0.040598202496767044, 0.0417570136487484, 0.03569822013378143, 0.0382370799779892, 0.04380952939391136, 0.03586716204881668, 0.0315852127969265, 0.029068943113088608, 0.03797413408756256, 0.027580613270401955, 0.02941048890352249, 0.027815427631139755, 0.02498169243335724, 0.02396005392074585, 0.028060344979166985, 0.02285463735461235, 0.021458690986037254, 0.02081282064318657, 0.023784415796399117, 0.02022683061659336, 0.031169766560196877, 0.022706545889377594, 0.021731963381171227, 0.020788896828889847, 0.024717966094613075, 0.019266333431005478, 0.017156247049570084, 0.02056329883635044, 0.027482859790325165, 0.016384249553084373, 0.0161894503980875, 0.015563328750431538, 0.019979244098067284, 0.016835220158100128, 0.015573879703879356, 0.02232355624437332, 0.01444750651717186, 0.0172820296138525, 0.02907339110970497, 0.018051398918032646, 0.01359704788774252, 0.016524070873856544, 0.013000364415347576, 0.012701166793704033, 0.02452053129673004, 0.013017706573009491, 0.012223001569509506, 0.01286007184535265, 0.011739222332835197, 0.012094796635210514, 0.01450636237859726, 0.031417034566402435, 0.018975969403982162, 0.01255797129124403, 0.011059030890464783, 0.010918310843408108, 0.013800541870296001, 0.03396093472838402, 0.013518902473151684, 0.010721483267843723, 0.012917027808725834, 0.010072044096887112, 0.015107179991900921, 0.01026760321110487, 0.010618781670928001, 0.013961166143417358, 0.010280323214828968, 0.00959048792719841, 0.010743494145572186, 0.009266049601137638, 0.010009057819843292, 0.015150290913879871, 0.01011603232473135, 0.009509789757430553, 0.01670778915286064, 0.009496763348579407, 0.009962515905499458, 0.008538242429494858, 0.01167579460889101, 0.010307562537491322, 0.008077721111476421, 0.010140075348317623, 0.008282807655632496, 0.008579022251069546, 0.00825026910752058, 0.008119504898786545, 0.00866066012531519, 0.010905131697654724, 0.007789794821292162, 0.008233950473368168, 0.009480707347393036, 0.009405730292201042, 0.00755337392911315, 0.009791710413992405, 0.007923237048089504, 0.007460028398782015, 0.016691971570253372, 0.008072701282799244, 0.008441278710961342, 0.010950060561299324, 0.007728861179202795, 0.007120673079043627, 0.009384825825691223, 0.007208478637039661, 0.007079854607582092, 0.007225988898426294, 0.007582427002489567, 0.007122488226741552, 0.0070344870910048485, 0.009322529658675194, 0.010443528182804585, 0.007926533930003643, 0.0071405950002372265, 0.007141292095184326, 0.007086388301104307, 0.007127371616661549, 0.008804856799542904, 0.009911308996379375, 0.006636122241616249, 0.009774575009942055, 0.0070633552968502045, 0.007494622841477394, 0.008093020878732204, 0.006507377605885267, 0.007707599084824324, 0.00677567720413208, 0.00670427642762661, 0.006837096065282822, 0.009291923604905605, 0.007706947159022093, 0.006648315116763115, 0.006387950386852026, 0.008662864565849304, 0.0063121505081653595, 0.006200248375535011, 0.008947666734457016, 0.00602993369102478, 0.005875994451344013, 0.006462932098656893, 0.0065300352871418, 0.006312146782875061, 0.008910993114113808, 0.006145937833935022, 0.006259042304009199, 0.009618551470339298, 0.006331834010779858, 0.006455149967223406, 0.006079984363168478, 0.006342967972159386, 0.010490607470273972, 0.006280791945755482, 0.0069176084361970425, 0.006133663933724165, 0.007163133472204208, 0.006446030922234058, 0.006356870289891958, 0.006212000735104084, 0.007593181915581226, 0.008970675058662891, 0.005946419667452574, 0.03866869956254959, 0.005611346568912268, 0.0066495477221906185, 0.0062111904844641685, 0.005583924241364002, 0.005627874284982681, 0.005494201555848122, 0.00540670333430171, 0.0055573261342942715, 0.005735042039304972, 0.006957146339118481, 0.006226113997399807, 0.005905464291572571, 0.006043287459760904, 0.006837522145360708, 0.006979646626859903, 0.0064522637985646725, 0.014842602424323559, 0.006335532758384943, 0.00631944602355361, 0.007837142795324326, 0.00772941205650568, 0.005952478386461735, 0.007418750319629908, 0.006069837603718042, 0.006591768469661474, 0.0065612830221652985, 0.007394644431769848, 0.0061101773753762245, 0.0060304906219244, 0.008761728182435036, 0.0063926116563379765, 0.008350330404937267, 0.005768762901425362, 0.005603502504527569, 0.007166858296841383, 0.005740259774029255, 0.005135368090122938, 0.005502813495695591, 0.006453488487750292, 0.0050365556962788105, 0.006073825526982546, 0.0063188751228153706, 0.009257109835743904, 0.0062148598954081535, 0.05278467386960983, 0.005962619557976723, 0.0063966563902795315, 0.005257530603557825, 0.005761837586760521, 0.007317292504012585, 0.037969883531332016, 0.005486326292157173, 0.00560242123901844, 0.006760698277503252, 0.005768833216279745, 0.006072880234569311, 0.007941952906548977, 0.008725003339350224, 0.004560939501971006, 0.004514085128903389, 0.00559465354308486, 0.004253611899912357, 0.004660825245082378, 0.005176393780857325, 0.004787740297615528, 0.004774471744894981, 0.005002805031836033, 0.0072796279564499855, 0.0047638071700930595, 0.0052886237390339375, 0.007035546470433474, 0.005569865927100182, 0.00593602517619729, 0.00532198790460825, 0.006482808385044336, 0.006301828660070896, 0.00567174656316638, 0.006228163372725248, 0.004949402064085007, 0.005972629878669977, 0.0061427331529557705, 0.005419124849140644, 0.006147267296910286, 0.006031543016433716, 0.0062989783473312855, 0.006223933305591345, 0.005455303937196732, 0.0055586728267371655, 0.01319810189306736, 0.004900738596916199, 0.005100614856928587, 0.005923662334680557, 0.0058524333871901035, 0.005865612532943487, 0.03434690460562706, 0.005566038191318512, 0.005608917213976383, 0.006149175576865673, 0.007250803988426924, 0.005999064538627863, 0.005670764483511448, 0.007369386497884989, 0.005847068969160318, 0.0060948957689106464, 0.00699378177523613, 0.006156031507998705, 0.006430445704609156, 0.006024195812642574, 0.005634715314954519, 0.00934414379298687, 0.009289450012147427, 0.005136700812727213, 0.005322133656591177, 0.005551682785153389, 0.006123150698840618, 0.005114904139190912, 0.005132777150720358, 0.006010591983795166, 0.008668355643749237, 0.005616915412247181, 0.005776848178356886, 0.006341469008475542, 0.006953071802854538, 0.03589580953121185, 0.004638472571969032, 0.005086853634566069, 0.005181977525353432, 0.0041700685396790504, 0.004339245613664389, 0.00576277170330286, 0.005761085543781519, 0.005363541655242443, 0.0055640083737671375, 0.006242191884666681, 0.005704514682292938, 0.006773593369871378, 0.004963538609445095, 0.005037067923694849, 0.0060546742752194405, 0.006444742903113365, 0.005270262248814106, 0.006026205141097307, 0.0066449278965592384, 0.0050583998672664165, 0.005801806226372719, 0.0057819914072752, 0.005892707500606775, 0.007107400801032782, 0.007272184826433659, 0.005174221470952034, 0.004854916129261255, 0.004773927386850119, 0.006319722160696983, 0.007785515859723091, 0.0062778363935649395, 0.005974192637950182, 0.0064177317544817924, 0.007124694064259529, 0.00650846166536212, 0.006592244375497103, 0.005835650954395533, 0.006456049624830484, 0.007209792733192444, 0.0050164624117314816, 0.006012896075844765, 0.0063014281913638115, 0.006211495958268642, 0.005830660462379456, 0.006720708217471838, 0.010299687273800373, 0.011144887655973434, 0.02506532520055771, 0.007011170964688063, 0.005278050433844328, 0.004606863483786583, 0.005332642700523138, 0.0056493887677788734, 0.0055970665998756886, 0.005147761665284634, 0.0039628068916499615, 0.00555699598044157, 0.005501607898622751, 0.005578316282480955], 'val_accuracy': [0.9241666793823242, 0.903333306312561, 0.9175000190734863, 0.903333306312561, 0.9141666889190674, 0.9183333516120911, 0.9024999737739563, 0.925000011920929, 0.9166666865348816, 0.925000011920929, 0.9150000214576721, 0.9316666722297668, 0.9083333611488342, 0.9375, 0.9283333420753479, 0.9225000143051147, 0.9225000143051147, 0.9258333444595337, 0.909166693687439, 0.9008333086967468, 0.9333333373069763, 0.940833330154419, 0.9433333277702332, 0.909166693687439, 0.9233333468437195, 0.9416666626930237, 0.940833330154419, 0.9350000023841858, 0.9233333468437195, 0.9350000023841858, 0.92166668176651, 0.9466666579246521, 0.934166669845581, 0.9491666555404663, 0.9474999904632568, 0.9474999904632568, 0.9483333230018616, 0.9325000047683716, 0.95333331823349, 0.9549999833106995, 0.9558333158493042, 0.9574999809265137, 0.9674999713897705, 0.9674999713897705, 0.9741666913032532, 0.9750000238418579, 0.9775000214576721, 0.9758333563804626, 0.9758333563804626, 0.9825000166893005, 0.98416668176651, 0.9833333492279053, 0.9883333444595337, 0.9925000071525574, 0.9833333492279053, 0.9941666722297668, 0.9916666746139526, 0.9941666722297668, 0.9933333396911621, 0.9916666746139526, 0.9891666769981384, 0.9950000047683716, 0.9933333396911621, 0.9933333396911621, 0.9916666746139526, 0.9933333396911621, 0.9950000047683716, 0.9950000047683716, 0.9941666722297668, 0.9941666722297668, 0.9950000047683716, 0.9950000047683716, 0.9933333396911621, 0.9941666722297668, 0.9958333373069763, 0.9958333373069763, 0.9933333396911621, 0.9950000047683716, 0.9950000047683716, 0.9950000047683716, 0.9950000047683716, 0.9950000047683716, 0.9950000047683716, 0.9950000047683716, 0.9941666722297668, 0.9950000047683716, 0.996666669845581, 0.996666669845581, 0.9950000047683716, 0.996666669845581, 0.996666669845581, 0.9950000047683716, 0.996666669845581, 0.9950000047683716, 0.9933333396911621, 0.9950000047683716, 0.996666669845581, 0.9950000047683716, 0.996666669845581, 0.996666669845581, 0.9941666722297668, 0.9983333349227905, 0.996666669845581, 0.9975000023841858, 0.996666669845581, 0.996666669845581, 0.996666669845581, 0.9908333420753479, 0.9941666722297668, 0.9975000023841858, 0.996666669845581, 0.9983333349227905, 0.996666669845581, 0.9891666769981384, 0.996666669845581, 0.996666669845581, 0.9975000023841858, 0.996666669845581, 0.996666669845581, 0.9983333349227905, 0.9975000023841858, 0.996666669845581, 0.9983333349227905, 0.9983333349227905, 0.9983333349227905, 0.9983333349227905, 0.9975000023841858, 0.996666669845581, 0.9975000023841858, 0.9983333349227905, 0.9950000047683716, 0.9975000023841858, 0.9983333349227905, 0.9983333349227905, 0.9975000023841858, 0.9983333349227905, 0.9983333349227905, 0.9983333349227905, 0.9991666674613953, 0.9975000023841858, 0.9991666674613953, 0.9975000023841858, 0.9983333349227905, 0.9975000023841858, 0.9991666674613953, 0.9991666674613953, 0.9975000023841858, 0.9983333349227905, 0.9991666674613953, 0.9975000023841858, 0.9991666674613953, 0.9975000023841858, 0.9958333373069763, 0.9983333349227905, 0.9983333349227905, 0.996666669845581, 0.9991666674613953, 0.9991666674613953, 0.9975000023841858, 0.9975000023841858, 0.9991666674613953, 0.9975000023841858, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.996666669845581, 0.9975000023841858, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9975000023841858, 0.9991666674613953, 0.9983333349227905, 0.9950000047683716, 0.9991666674613953, 0.9975000023841858, 0.9991666674613953, 0.9975000023841858, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9975000023841858, 0.9975000023841858, 0.9991666674613953, 0.9991666674613953, 0.9983333349227905, 0.996666669845581, 0.9983333349227905, 0.9991666674613953, 0.9983333349227905, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.996666669845581, 0.9991666674613953, 0.9991666674613953, 0.9983333349227905, 0.9991666674613953, 0.9975000023841858, 0.9991666674613953, 0.9991666674613953, 0.996666669845581, 0.9991666674613953, 0.996666669845581, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9950000047683716, 0.9991666674613953, 0.9883333444595337, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9983333349227905, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9941666722297668, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9975000023841858, 0.996666669845581, 0.9991666674613953, 0.9991666674613953, 0.996666669845581, 0.9991666674613953, 0.996666669845581, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9958333373069763, 0.9991666674613953, 0.98416668176651, 0.9991666674613953, 0.996666669845581, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9883333444595337, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9975000023841858, 0.9983333349227905, 0.9983333349227905, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9975000023841858, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9975000023841858, 0.9983333349227905, 0.9983333349227905, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9916666746139526, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9983333349227905, 0.9983333349227905, 0.9983333349227905, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9933333396911621, 0.9975000023841858, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9983333349227905, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9983333349227905, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9950000047683716, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953, 0.9991666674613953]}\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.0033 - accuracy: 0.9992\n",
            "loss, accuracy= [0.0033095336984843016, 0.9991666674613953]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "It cost 2477.095455 sec\n",
            "2477.095454931259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "TJdiNbSYYcyl",
        "outputId": "8d1d843c-0fb4-4833-e2a2-17bbf8640654"
      },
      "source": [
        "\n",
        "prediction = model.predict_classes(X_test)\n",
        "def show_train_history(train_history, train, validation):  # 訓練集驗證準確度對epoch做圖\n",
        "    plt.plot(train_history.history[train])  # 绘制训练数据的执行结果\n",
        "    plt.plot(train_history.history[validation])  # 绘制验证数据的执行结果\n",
        "    plt.title('Train History')  # 图标题\n",
        "    plt.xlabel('epoch')  # x轴标签\n",
        "    plt.ylabel(train)  # y轴标签\n",
        "    plt.legend(['train', 'validation'], loc='upper left')  # 添加左上角图例\n",
        "    plt.show()\n",
        "\n",
        "show_train_history(train_history, 'accuracy', 'val_accuracy')\n",
        "\n",
        "show_train_history(train_history, 'loss', 'val_loss')\n",
        "\n",
        "print(pd.crosstab(y_test_label,prediction,rownames=['label'],colnames=['predict']))   # https://zhuanlan.zhihu.com/p/52368125  其他呈現交叉表方法(平均、彩色圖...)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "predict    0    1\n",
            "label            \n",
            "0        600    0\n",
            "1          1  599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RQ6PV4idH4Q5",
        "outputId": "96e364b2-5789-4e4c-f8c4-e0618a44bf64"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"my_model2.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_28dd6cdc-87b9-430e-99d6-b45d0ab24453\", \"my_model2.h5\", 819624)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}